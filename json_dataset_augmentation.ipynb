{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "318f3f6cdd5149a4b6c3bc7b68a46b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42795a80854a497aaa50757762b4e21e",
              "IPY_MODEL_52fc584c4d9c4b1e85d71f7001c6321c",
              "IPY_MODEL_e6b20a2c7a214a09885ae5f0dfec79aa"
            ],
            "layout": "IPY_MODEL_6338da21f6e2441fa3007780d065d88f"
          }
        },
        "42795a80854a497aaa50757762b4e21e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ba932a78cfb46db98402106832286fc",
            "placeholder": "​",
            "style": "IPY_MODEL_6a61794c071c4cccb5fee986f0a345dc",
            "value": "Processing Images: 100%"
          }
        },
        "52fc584c4d9c4b1e85d71f7001c6321c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbadb0aad92f43a29be0ce4ba17216d6",
            "max": 10921,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6230100903ec48ebb8cba7434c14e025",
            "value": 10921
          }
        },
        "e6b20a2c7a214a09885ae5f0dfec79aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f1e3df1c9f144e5ad9f34a9222345f9",
            "placeholder": "​",
            "style": "IPY_MODEL_0eb9b27a58db458281f997dcd60cee69",
            "value": " 10921/10921 [36:29&lt;00:00,  3.75it/s]"
          }
        },
        "6338da21f6e2441fa3007780d065d88f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba932a78cfb46db98402106832286fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a61794c071c4cccb5fee986f0a345dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbadb0aad92f43a29be0ce4ba17216d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6230100903ec48ebb8cba7434c14e025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f1e3df1c9f144e5ad9f34a9222345f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eb9b27a58db458281f997dcd60cee69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install Java 17\n",
        "# language_tool_python requires Java >= 17. Colab often defaults to Java 11.\n",
        "!apt-get update\n",
        "!apt-get install -y openjdk-17-jdk-headless\n",
        "!update-alternatives --set java /usr/lib/jvm/java-17-openjdk-amd64/bin/java\n",
        "!java -version\n",
        "\n",
        "print(\"Java 17 installed and set as default.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvRfxe7Ps8AZ",
        "outputId": "4dff1f60-3060-4e8c-f2c9-d1a59689772f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r            \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 3,632 B/3,632 B 100\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 3,632 B/3,632 B 100\r0% [Waiting for headers] [Waiting for headers] [Connected to r2u.stat.illinois.\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Waiting for headers] [3 InRelease 14.2 kB/129 kB 11%] [Connected to r2u.sta\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,853 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,269 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,770 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,574 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,160 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,471 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,147 kB]\n",
            "Fetched 23.6 MB in 3s (7,789 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  openjdk-17-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-17-demo openjdk-17-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  | fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-17-jdk-headless openjdk-17-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 120 MB of archives.\n",
            "After this operation, 272 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre-headless amd64 17.0.15+6~us1-0ubuntu1~22.04 [48.3 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk-headless amd64 17.0.15+6~us1-0ubuntu1~22.04 [71.3 MB]\n",
            "Fetched 120 MB in 4s (33.4 MB/s)\n",
            "Selecting previously unselected package openjdk-17-jre-headless:amd64.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-17-jre-headless_17.0.15+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jre-headless:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-17-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-17-jdk-headless_17.0.15+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk-headless:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "Setting up openjdk-17-jre-headless:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
            "Setting up openjdk-17-jdk-headless:amd64 (17.0.15+6~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
            "openjdk version \"17.0.15\" 2025-04-15\n",
            "OpenJDK Runtime Environment (build 17.0.15+6-Ubuntu-0ubuntu122.04)\n",
            "OpenJDK 64-Bit Server VM (build 17.0.15+6-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n",
            "Java 17 installed and set as default.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gbZLqG6quJW",
        "outputId": "fa899038-d7ea-4d53-a2f5-3b8a76c0f4bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: language_tool_python in /usr/local/lib/python3.11/dist-packages (2.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (5.9.5)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (0.10.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (2025.7.14)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Required Python libraries installed.\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Install Required Python Libraries\n",
        "\n",
        "!pip install language_tool_python\n",
        "!pip install transformers # For potential VLM use (e.g., BLIP/GIT if running locally)\n",
        "!pip install openai       # For GPT-4 API (if using)\n",
        "!pip install nltk         # For tokenization, though simple split() is used for this example\n",
        "!pip install scikit-learn # For TF-IDF and cosine similarity\n",
        "!pip install tqdm         # For progress bar\n",
        "\n",
        "print(\"Required Python libraries installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Import Libraries and Mount Google Drive\n",
        "\n",
        "import json\n",
        "import re\n",
        "import language_tool_python\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm.notebook import tqdm # For progress bar in Colab\n",
        "\n",
        "# Optional: For LLM/VLM integration later, if running locally (e.g., BLIP/GIT)\n",
        "# from transformers import pipeline, set_seed\n",
        "# from PIL import Image\n",
        "\n",
        "# For OpenAI API (if using)\n",
        "# import openai\n",
        "# import os\n",
        "\n",
        "# Mount Google Drive\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "    # Define file paths. ADJUST THESE PATHS to where your files are located.\n",
        "    # >>>>>> IMPORTANT: ENSURE THESE PATHS ARE CORRECT FOR YOUR FILE LOCATION <<<<<<\n",
        "    json_file_path = '/content/dataset_rsicd.json' # <--- ADJUST THIS!\n",
        "    output_file_path = '/content/drive/MyDrive/captions_train_augmented.json' # <--- ADJUST THIS!\n",
        "except ImportError:\n",
        "    print(\"Not in Google Colab environment. Please adjust file paths.\")\n",
        "    json_file_path = 'dataset_rsicd.json' # Example for local execution\n",
        "    output_file_path = 'captions_train_augmented.json'\n",
        "\n",
        "print(f\"Input JSON path: {json_file_path}\")\n",
        "print(f\"Output JSON path: {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXhyoOSLq9u_",
        "outputId": "640a5e8f-41a7-45b1-8e4e-51ec2559eabc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully.\n",
            "Input JSON path: /content/dataset_rsicd.json\n",
            "Output JSON path: /content/drive/MyDrive/captions_train_augmented.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Load Dataset and Initialize LanguageTool\n",
        "\n",
        "# Load the Dataset\n",
        "try:\n",
        "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    print(f\"Successfully loaded {len(data['images'])} images from {json_file_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Input JSON file '{json_file_path}' not found. Please double-check the path in Cell 3.\")\n",
        "    data = {\"images\": []} # Fallback to prevent immediate crash, but main processing will skip\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Error: Could not decode JSON from '{json_file_path}'. Check file format for validity.\")\n",
        "    data = {\"images\": []}\n",
        "\n",
        "# Initialize LanguageTool (this may still take a moment, but now with correct Java)\n",
        "print(\"\\nInitializing LanguageTool for grammar correction (this may take a moment)...\")\n",
        "lang_tool = language_tool_python.LanguageTool('en-US') # You can change to 'en-GB' if preferred\n",
        "print(\"LanguageTool initialized.\")\n",
        "\n",
        "# Find the maximum existing sentid to ensure uniqueness for new captions\n",
        "next_sentid = 0\n",
        "if 'images' in data:\n",
        "    for img_data in data['images']:\n",
        "        for sent in img_data.get('sentences', []):\n",
        "            if 'sentid' in sent and sent['sentid'] >= next_sentid:\n",
        "                next_sentid = sent['sentid'] + 1\n",
        "print(f\"Starting new sentence ID (sentid) assignment from: {next_sentid}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoBHyr8fruoF",
        "outputId": "8f4e9c5a-e643-49bd-9865-7c614e9c2af3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 10921 images from /content/dataset_rsicd.json\n",
            "\n",
            "Initializing LanguageTool for grammar correction (this may take a moment)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading LanguageTool latest: 100%|██████████| 252M/252M [00:08<00:00, 30.9MB/s]\n",
            "INFO:language_tool_python.download_lt:Unzipping /tmp/tmp4zkg3dg_.zip to /root/.cache/language_tool_python.\n",
            "INFO:language_tool_python.download_lt:Downloaded https://internal1.languagetool.org/snapshots/LanguageTool-latest-snapshot.zip to /root/.cache/language_tool_python.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LanguageTool initialized.\n",
            "Starting new sentence ID (sentid) assignment from: 54605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Define Helper Functions (Text Similarity & Duplicate Filtering)\n",
        "\n",
        "def get_sentence_embeddings(sentences):\n",
        "    \"\"\"Generates TF-IDF vectors for sentences for similarity comparison.\"\"\"\n",
        "    if not sentences:\n",
        "        return None, None\n",
        "    # Adjust min_df to ignore terms that appear too infrequently\n",
        "    vectorizer = TfidfVectorizer(min_df=1, stop_words='english').fit(sentences)\n",
        "    tfidf_matrix = vectorizer.transform(sentences)\n",
        "    return tfidf_matrix, vectorizer\n",
        "\n",
        "def filter_duplicates_by_similarity(new_captions_to_check, existing_captions_baseline, threshold=0.9):\n",
        "    \"\"\"\n",
        "    Filters out new captions that are too similar to existing ones or to each other.\n",
        "\n",
        "    Args:\n",
        "        new_captions_to_check (list): List of new raw captions to be filtered.\n",
        "        existing_captions_baseline (list): List of raw captions already present (cleaned originals).\n",
        "        threshold (float): Cosine similarity threshold. Captions above this are considered duplicates.\n",
        "\n",
        "    Returns:\n",
        "        list: Filtered list of new captions.\n",
        "    \"\"\"\n",
        "    if not new_captions_to_check:\n",
        "        return []\n",
        "\n",
        "    # Combine all captions for TF-IDF vectorization\n",
        "    all_captions = existing_captions_baseline + new_captions_to_check\n",
        "\n",
        "    if len(all_captions) < 2:\n",
        "        return new_captions_to_check # Not enough captions to compare\n",
        "\n",
        "    tfidf_matrix, vectorizer = get_sentence_embeddings(all_captions)\n",
        "    if tfidf_matrix is None: # No features found\n",
        "        return new_captions_to_check\n",
        "\n",
        "    # Compute cosine similarity for all pairs\n",
        "    cosine_sim_matrix = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "    filtered_new_captions = []\n",
        "    # Indices of new captions start after the existing ones\n",
        "    new_captions_start_idx = len(existing_captions_baseline)\n",
        "\n",
        "    # Keep track of indices that are already considered 'kept' to avoid adding very similar new captions\n",
        "    kept_indices_in_all_captions = list(range(new_captions_start_idx)) # Initially, all baseline captions are 'kept'\n",
        "\n",
        "    for i in range(len(new_captions_to_check)):\n",
        "        current_new_caption_idx = new_captions_start_idx + i\n",
        "        is_duplicate = False\n",
        "        # Compare current new caption against all captions already in 'kept_indices_in_all_captions'\n",
        "        for j in kept_indices_in_all_captions:\n",
        "            if cosine_sim_matrix[current_new_caption_idx, j] >= threshold:\n",
        "                is_duplicate = True\n",
        "                break\n",
        "        if not is_duplicate:\n",
        "            filtered_new_captions.append(new_captions_to_check[i])\n",
        "            kept_indices_in_all_captions.append(current_new_caption_idx) # Add current caption to 'kept' set\n",
        "\n",
        "    return filtered_new_captions\n",
        "\n",
        "print(\"Helper functions for text similarity and duplicate filtering defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQSCJedDr0Ej",
        "outputId": "5aef66b6-515d-401d-f3ac-3123732c7904"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helper functions for text similarity and duplicate filtering defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Main Processing Loop (Cleaning, Grammar, Enrichment, Normalization)\n",
        "\n",
        "processed_images = []\n",
        "normalization_map = {\n",
        "    \"residential area\": \"neighborhood\",\n",
        "    \"railway\": \"train tracks\",\n",
        "    \"road\": \"street\",\n",
        "    \"cars\": \"vehicles\",\n",
        "    \"plane\": \"aircraft\",\n",
        "    \"planes\": \"aircraft\",\n",
        "    \"building\": \"structure\",\n",
        "    \"buildings\": \"structures\",\n",
        "    \"court\": \"field\", # Example based on project description \"An old court is surrounded by white houses.\"\n",
        "    \"football field\": \"sports field\",\n",
        "    \"basketball court\": \"sports field\",\n",
        "    \"tennis court\": \"sports field\"\n",
        "    # Add more mappings as you analyze your dataset's vocabulary\n",
        "}\n",
        "\n",
        "# --- Main Processing Loop ---\n",
        "# Using tqdm for a progress bar in Colab\n",
        "if 'images' in data and len(data['images']) > 0:\n",
        "    for i, img_data in tqdm(enumerate(data['images']), total=len(data['images']), desc=\"Processing Images\"):\n",
        "        current_filename = img_data['filename']\n",
        "        current_imgid = img_data['imgid']\n",
        "        original_sentences = img_data.get('sentences', [])\n",
        "        processed_sentences_initial = [] # Will hold cleaned and grammar-fixed original captions\n",
        "        existing_raw_captions_for_sim = [] # For similarity filtering against new captions\n",
        "\n",
        "        # --- 1. Clean Captions & 2. Grammar Fix ---\n",
        "        for sent in original_sentences:\n",
        "            cleaned_raw = sent['raw'].lower().strip()\n",
        "            cleaned_raw = re.sub(r'\\s+', ' ', cleaned_raw) # Remove multiple spaces\n",
        "            cleaned_raw = re.sub(r'([.!?])\\1+', r'\\1', cleaned_raw) # Fix duplicate punctuation\n",
        "            if not cleaned_raw.endswith(('.', '!', '?')):\n",
        "                cleaned_raw += '.' # Ensure ends with punctuation\n",
        "\n",
        "            # Apply grammar correction\n",
        "            matches = lang_tool.check(cleaned_raw)\n",
        "            grammatically_fixed_caption = language_tool_python.utils.correct(cleaned_raw, matches)\n",
        "\n",
        "            processed_sentences_initial.append({\n",
        "                'original_sentid': sent['sentid'], # Keep original ID to link back\n",
        "                'raw': grammatically_fixed_caption\n",
        "            })\n",
        "            existing_raw_captions_for_sim.append(grammatically_fixed_caption)\n",
        "\n",
        "        # --- 3. Caption Enrichment ---\n",
        "        # This is the placeholder where you integrate your LLM/VLM call.\n",
        "        # Replace this section with your actual code for GPT-4 or BLIP/GIT.\n",
        "        newly_generated_captions = []\n",
        "\n",
        "        # Example placeholder for LLM call (replace this with your real LLM/VLM logic)\n",
        "        # --- START OF LLM/VLM INTEGRATION ---\n",
        "        # Example using a dummy generator (replace this with your real LLM/VLM logic):\n",
        "        # For a real implementation, you'd loop through existing_raw_captions_for_sim or use the image itself\n",
        "        if i % 100 == 0: # Only generate for a few images to demonstrate, adjust as needed\n",
        "            for original_cap in existing_raw_captions_for_sim[:1]: # Take first original caption for example\n",
        "                # Replace with your actual API call or model inference\n",
        "                # For GPT-4 example:\n",
        "                # try:\n",
        "                #     openai.api_key = \"YOUR_OPENAI_API_KEY\" # Replace with your actual key or os.getenv()\n",
        "                #     response = openai.chat.completions.create(\n",
        "                #         model=\"gpt-4\",\n",
        "                #         messages=[\n",
        "                #             {\"role\": \"system\", \"content\": \"You are a creative assistant providing diverse descriptions for remote sensing images.\"},\n",
        "                #             {\"role\": \"user\", \"content\": f\"Generate 2 new, diverse, and concise paraphrases for this remote sensing image caption: '{original_cap}'\"}\n",
        "                #         ],\n",
        "                #         n=2, # Request 2 paraphrases\n",
        "                #         temperature=0.8 # Higher temperature for more diversity\n",
        "                #     )\n",
        "                #     for choice in response.choices:\n",
        "                #         gen_text = choice.message.content.strip()\n",
        "                #         # Apply basic cleaning to generated text\n",
        "                #         gen_text = re.sub(r'\\s+', ' ', re.sub(r'([.!?])\\1+', r'\\1', gen_text.lower().strip()))\n",
        "                #         newly_generated_captions.append(gen_text)\n",
        "                # except Exception as e:\n",
        "                #     print(f\"Warning: Error generating captions for '{current_filename}': {e}\")\n",
        "                #     # Handle API rate limits, connection errors etc.\n",
        "\n",
        "                # Simple synthetic generation for demonstration if no LLM/VLM is set up\n",
        "                if \"airport\" in current_filename.lower() and len(newly_generated_captions) < 2:\n",
        "                    newly_generated_captions.append(f\"an aerial view of a bustling {current_filename.split('_')[0]} with numerous runways.\")\n",
        "                    newly_generated_captions.append(f\"the scene depicts an active {current_filename.split('_')[0]} facility from above.\")\n",
        "                elif \"playground\" in current_filename.lower() and len(newly_generated_captions) < 2:\n",
        "                    newly_generated_captions.append(f\"a recreational ground with various play structures visible from the air.\")\n",
        "                    newly_generated_captions.append(f\"overhead shot of a park area featuring playground equipment.\")\n",
        "                elif len(newly_generated_captions) < 2:\n",
        "                    newly_generated_captions.append(f\"a remote sensing image showing a {current_filename.split('_')[0]} area.\")\n",
        "                    newly_generated_captions.append(f\"the image captures the {current_filename.split('_')[0]} from an aerial perspective.\")\n",
        "\n",
        "        # --- END OF LLM/VLM INTEGRATION ---\n",
        "\n",
        "        # Filter newly generated captions for diversity and remove duplicates against existing ones\n",
        "        filtered_new_captions = filter_duplicates_by_similarity(\n",
        "            new_captions_to_check=newly_generated_captions,\n",
        "            existing_captions_baseline=existing_raw_captions_for_sim,\n",
        "            threshold=0.9 # ADJUST THIS THRESHOLD based on desired similarity\n",
        "        )\n",
        "\n",
        "\n",
        "        # --- 4. Token Normalization ---\n",
        "        all_captions_for_normalization = \\\n",
        "            [s['raw'] for s in processed_sentences_initial] + \\\n",
        "            [cap for cap in filtered_new_captions] # Add filtered new captions\n",
        "\n",
        "        normalized_final_captions_raw = []\n",
        "        for caption_text in all_captions_for_normalization:\n",
        "            normalized_caption = caption_text\n",
        "            for old_term, new_term in normalization_map.items():\n",
        "                # Use regex with word boundaries to replace whole words/phrases, case-insensitively\n",
        "                normalized_caption = re.sub(r'\\b' + re.escape(old_term) + r'\\b', new_term, normalized_caption, flags=re.IGNORECASE)\n",
        "            normalized_final_captions_raw.append(normalized_caption)\n",
        "\n",
        "        # Re-assemble all captions for the image, assigning new sentids where necessary\n",
        "        final_processed_sentences_for_image = []\n",
        "        current_img_sentids = []\n",
        "\n",
        "        # Add processed original captions\n",
        "        for j, sent_data in enumerate(processed_sentences_initial):\n",
        "            normalized_raw = normalized_final_captions_raw[j]\n",
        "            final_processed_sentences_for_image.append({\n",
        "                'tokens': normalized_raw.split(),\n",
        "                'raw': normalized_raw,\n",
        "                'imgid': current_imgid,\n",
        "                'sentid': sent_data['original_sentid'] # Retain original sentids for original captions\n",
        "            })\n",
        "            current_img_sentids.append(sent_data['original_sentid'])\n",
        "\n",
        "        # Add filtered and normalized new captions\n",
        "        for j, new_caption_raw in enumerate(normalized_final_captions_raw[len(processed_sentences_initial):]):\n",
        "            final_processed_sentences_for_image.append({\n",
        "                'tokens': new_caption_raw.split(),\n",
        "                'raw': new_caption_raw,\n",
        "                'imgid': current_imgid,\n",
        "                'sentid': next_sentid # Assign unique new sentid for augmented captions\n",
        "            })\n",
        "            current_img_sentids.append(next_sentid)\n",
        "            next_sentid += 1 # Increment for the next new sentence\n",
        "\n",
        "        # --- 6. Optional: Scene Class Metadata ---\n",
        "        # This is a basic example. For a robust solution, consider\n",
        "        # image classification or more sophisticated text-based scene inference.\n",
        "        scene_label = \"unknown\"\n",
        "        if \"_\" in current_filename:\n",
        "            # Tries to infer scene from filename (e.g., \"airport_1.jpg\" -> \"airport\")\n",
        "            # You'll need to verify if this is accurate for your dataset.\n",
        "            scene_label = current_filename.split('_')[0].lower()\n",
        "        # Add more rules or a lookup table here for scene inference if needed\n",
        "        # e.g., if \"stadium\" in any caption, scene_label = \"sports_stadium\"\n",
        "\n",
        "\n",
        "        # Prepare the image entry for the new JSON structure\n",
        "        processed_image_entry = {\n",
        "            'filename': current_filename,\n",
        "            'imgid': current_imgid,\n",
        "            'sentences': final_processed_sentences_for_image,\n",
        "            'split': img_data.get('split', 'unknown'), # Preserve original split, default if missing\n",
        "            'sentids': current_img_sentids,\n",
        "            'scene': scene_label # Add optional scene metadata\n",
        "        }\n",
        "        processed_images.append(processed_image_entry)\n",
        "\n",
        "    print(\"\\nFinished processing all images.\")\n",
        "else:\n",
        "    print(\"No images found in the dataset to process. Please check the JSON file and its path.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "318f3f6cdd5149a4b6c3bc7b68a46b42",
            "42795a80854a497aaa50757762b4e21e",
            "52fc584c4d9c4b1e85d71f7001c6321c",
            "e6b20a2c7a214a09885ae5f0dfec79aa",
            "6338da21f6e2441fa3007780d065d88f",
            "2ba932a78cfb46db98402106832286fc",
            "6a61794c071c4cccb5fee986f0a345dc",
            "fbadb0aad92f43a29be0ce4ba17216d6",
            "6230100903ec48ebb8cba7434c14e025",
            "3f1e3df1c9f144e5ad9f34a9222345f9",
            "0eb9b27a58db458281f997dcd60cee69"
          ]
        },
        "id": "BDhvZDcIr2br",
        "outputId": "14e06ae8-caa5-4c50-a44b-d8ae4121ece0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Images:   0%|          | 0/10921 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "318f3f6cdd5149a4b6c3bc7b68a46b42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Finished processing all images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Merge & Save as COCO-like JSON\n",
        "\n",
        "output_data = {'images': processed_images}\n",
        "\n",
        "try:\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(output_data, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"\\nSuccessfully saved augmented dataset to: {output_file_path}\")\n",
        "    print(f\"Total images processed: {len(processed_images)}\")\n",
        "    total_sentences = sum(len(img['sentences']) for img in processed_images)\n",
        "    print(f\"Total sentences in augmented dataset: {total_sentences}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving output file: {e}\")\n",
        "\n",
        "print(\"\\n--- Script Execution Complete ---\")\n",
        "print(\"Please review the generated captions and adjust parameters (like normalization_map, similarity threshold, and LLM prompts) as needed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb2NEU0Ar3j0",
        "outputId": "3765683b-a36f-4194-b921-8a52e703c19f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Successfully saved augmented dataset to: /content/drive/MyDrive/captions_train_augmented.json\n",
            "Total images processed: 10921\n",
            "Total sentences in augmented dataset: 54825\n",
            "\n",
            "--- Script Execution Complete ---\n",
            "Please review the generated captions and adjust parameters (like normalization_map, similarity threshold, and LLM prompts) as needed.\n"
          ]
        }
      ]
    }
  ]
}